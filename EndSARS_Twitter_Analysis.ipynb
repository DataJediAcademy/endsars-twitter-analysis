{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EndSARS Twitter Analysis\n",
    "\n",
    "Sentiment and Network Analysis of the #EndSARS protest movement that occured in 2020 in Nigeria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import csv\n",
    "import gensim\n",
    "import searchtweets\n",
    "import fastText as ft\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to Twitter\n",
    "\n",
    "I suggest you use Twitter's official searchtweets api which is easy to use and reliable.\n",
    "<br>In order to get past the tweets retrieval limit, you might also need to  use the premium search api."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a hidden yaml file (.yaml) which contains details about your twitter api keys\n",
    "- Create a variable that stores the twitter api credentials from the hiddem yaml file above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tweets():\n",
    "    \"\"\"\n",
    "    Create a function that gets tweets using the premium search API where matching a certain keyword during a\n",
    "    certain date range and returns all these tweets as a list\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tweets_df():\n",
    "    \"\"\"\n",
    "    Create a function that Creates a dataframe from the tweets you've retrieved using the retieve_tweets function \n",
    "    you created above. This functions should also take a list of datest you want to get tweets from\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the functions you've created above to collect all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list = [\"2017-01-05\", \"2016-01-05\",\n",
    "              \"2018-03-05\", \"2017-03-05\", \"2016-03-05\",\n",
    "              \"2017-06-05\", \"2016-06-05\",\n",
    "              \"2017-09-05\", \"2016-09-05\",\n",
    "              \"2017-11-05\", \"2016-11-05\", \"2015-11-05\"]\n",
    "\n",
    "tweets_df = create_tweets_df(dates_list)\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to save the tweets after this process, use a file format that won't comprimise the characters in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv(\"./data/endsars_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_duplicates(df, str_len=25):\n",
    "    \"\"\"\n",
    "    Create a function that looks at the tweets in the tweets dataframe and other characters and delete \n",
    "    duplicates as sometimes we can get duplicate data/tweets. For example if I tweet something and someone else\n",
    "    retweets it then this could possibly be a duplicate. Is this useful information? You need to decide of course.\n",
    "    \"\"\"\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Create a function that preprocess the text in a single tweet. Suggestions for this function are:\n",
    "    - correct all multiple white spaces to a single white space\n",
    "    - convert all urls to string \"URL\"\n",
    "    - if the username isn't relevant then convert @username to \"AT_USER\"\n",
    "    - converts emoji's to text description of the emoji\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df = delete_duplicates(tweets_to_analyse)\n",
    "tweets_df.reset_index(inplace=True, drop=True)\n",
    "tweets_df['text_clean'] = tweets_df['text'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets Analysis\n",
    "\n",
    "Now it's time to analyse this data to try and get some interesting insights. Below are some questions you can answer to get started but the best Data Scientists are creative thinkers so think out of th ebox to decide what will be interesting insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What locations in Nigeria and around the world were the hashtags popular?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How far did the hashtag reach and how deep was this reach?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When the did movement start on social media? When did it reach critical mass?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What were the most popular words or terms used during the movement?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Who were the key influences and proponents involved in the movement?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What was the most popular tweet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the general sentiment of the tweets about the movement? How has this changed from the start of the movement till now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Were there any bots or bad actors spreading fake news around the movement?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are some examples of this fake news?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Modelling\n",
    "Train model on labelled twitter sentiment data from another dataset\n",
    "<br>Next steps:\n",
    "- Download Sentiment140 data\n",
    "- preprocess tweet data\n",
    "- Apply word embeddings to the text\n",
    "- apply fasttext text classification\n",
    "- Pickle model\n",
    "- Apply model to endsars tweets text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data ready for fastText training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as .txt file for the fastText classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df, filename=\"\"):\n",
    "    \"\"\"\n",
    "    Create a functions that prepares the endsars data in a format that the fasttext model likes\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Modelto Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check labels on example tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply trained fastText model to tweets df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df['ft_predict'] = tweets_df.text.apply(ft_model.predict)\n",
    "tweets_df[\"sentiment\"] = tweets_df.ft_predict.apply(lambda x: 1 if x[0][0] == '__label__positive' else\n",
    "                                                               0)\n",
    "tweets_df['sentiment_prob'] = tweets_df.ft_predict.apply(lambda x: x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tweet_sentiment(index=0):\n",
    "    \"\"\"\n",
    "    Create function where you either pass the index of the tweet in the tweets_df or a tweet and it returns the \n",
    "    sentiment for the tweet\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:endsars] *",
   "language": "python",
   "name": "conda-env-endsars-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
